% !TEX root = tesis.tex

% \chapter{Theoretical Introduction}
\chapter{Theoretical Building Blocks}
\label{chap:theoretical_intro}

\section{Social Homophily}

\epigraph{``People love those who are like themselves.''}{\textit{Rhetoric \\ Aristotle}}

Similarity breeds connection~\cite{mcpherson2001birds}. People have several visible characteristics, such as age, gender, and socioeconomic status, for which contact between people with similar properties occurs at a higher rate than between dissimilar people.

There are two overall types of homophily that can be distinguished in groups~\cite{lazarsfeld1954}: \textit{status homophily}, in which similarity is based on status, and \textit{value homophily}, which is based on values, attitudes, and beliefs. Status homophily, a part of which is the main study of this thesis, includes the major sociodemographic dimensions that stratify society --- ascribed characteristics like race, ethnicity, sex, or age, and acquired characteristics like religion, education, occupation, and behaviour patterns.

\subsection{Age Homophily}

One of the most common homophily patterns in human relations is related to the people's ages~\cite{ugander2011}\cite{mcpherson2001birds}. This result is expected because of the many societal reasons that explain the homophily: schools tend to group people according to age into the same classrooms, work opportunities tend to be clustered into age groups, which affects work environments and neighbourhood composition, and people have a strong tendency to confide in someone of one's own age.

This correlation has a waterfall effect. Since this kind of homophily is present since early into people's life, the produced connections are closer, longer lived, have a larger number of exchanges, and tend to be more personal than other kinds of connections.

There's an interesting exception to this homophily: there is a significant number of connections between parents and their younger children~\cite{sarraute2014}. This exception is addressed later in this paper.

\subsection{Gender Homophily}

McPherson et.\ al.\ also noted an important degree of homophily between members of the same gender~\cite{mcpherson2001birds}. In particular, ever since school age children learn that gender is a permanent personal characteristic, homophily can be observed in play patterns and friend groups.

By the time people are adults, people's friendship networks are relatively gender-integrated. However, when controlling for kinship networks and not counting close family members, there is a considerable level of gender homophily~\cite{marsden_1988}. However, this level is still lower than the one for race, education, age, and many other social dimensions.

Gender homophily is lower among the young and the highly educated\cite{marsden_1987}. One of the main reasons for this is that most environments where people make their networks, such as work establishments and voluntary organizations, are highly sex segregated. Therefore, it's not surprising that the networks formed in these settings display a significant amount of baseline homophily on gender.

\section{Spearman's Coefficient}
\label{subsec:spearman}

Spearman's Rank Correlation Coefficient (also known as Spearman's rho) is a non-parametric measure of rank correlation which measures how well the relationship between two variables can be described using a monotonic function~\cite{statistical_analysis}. Unlike Pearson's Correlation Coefficient, which measures lineal relationship between variables, Spearman's Coefficient uses the \emph{rank} of the variables in its calculations; therefore is measures its monotonicity.

For a sample of size $n$ with scores $X_i$ and $Y_i$, the Spearman Coefficient $r_s$ is defined as in \cref{eq:spearman}.

\begin{equation}
r_s = \mathlarger{\rho}_{\rank(X) \rank(Y)} = \frac{\cov(\rank(x), \rank(y))}{\sigma_{\rank(X)} \sigma_{\rank(Y)}}
\label{eq:spearman}
\end{equation}

Where $\rho_{a,b}$ denotes the \emph{Pearson Correlation} between the variables $a$ and $b$. This value will be closer to 1 when the variables are directly monotonic, closer to -1 when they are inversely monotonic, and closer to 0 when there is no tendency for either variable to increase or decrease when the other increases.

\section{Bayesian Inference}

\epigraph{``Given the number of times in which an unknown event has happened and failed: required the chance that the probability of its happening in a single trial lies somewhere between any two degrees of probability that can be named.''}{\textit{An Essay towards solving a Problem in the Doctrine of Changes~\cite{bayes1763} \\ Thomas Bayes}}

This work uses a Bayesian approach to statistics instead of the usual Frequentist approach. In the Frequentist point of view, parameters are fixed and unknown: hypotheses are either true or false, and they cannot be described with a probability. In the Bayesian approach, anything unknown is described with a probability distribution since uncertainty must be described by probability~\cite{mackay}.

\subsection{Bayes Theorem}

The base of \emph{Bayesian Inference} is \emph{Bayes' Theorem}, presented in \cref{eq:bayes}, which describes the probability of an event base on prior knowledge of conditions that may be related to it~\cite{gelman2003}.

\begin{equation}
\label{eq:bayes}
	P \left( H \mid E \right) = \frac{P \left( E \mid H \right) \cdot P \left( H \right)}{P \left( E \right)}
\end{equation}

Each one of the terms in \cref{eq:bayes} has a different definition and interpretation.

\begin{itemize}
	\item $P \left( H \mid E \right)$, the \textbf{Posterior Probability} is the conditional probability that is assigned after the relevant evidence is taken into account.
	\item $P \left( H \right)$, the \textbf{Prior Probability}, expresses the assumptions made on the problem before the experiments. While these assumptions will be subjective, the same thing can be said about the other probabilities in this model.
	\item $P \left( E \mid H \right)$, the \textbf{Likelihood}, is the degree of belief in $E$ given that $H$ is true. In most real world problems, this tends to be easier to define than the \emph{Prior}.
	\item $P \left( E \right)$, the \textbf{Marginal Likelihood}, as the likelihood function where some parameter variables were marginalized. It's used as a normalizing constant to that the \emph{Posterior Probability} integrates to 1, thus making it a valid probability. Since it's constant on the perspective of $H$, it's usually ignored when taking proportionality, as in \cref{eq:bayes_propto}.
\end{itemize}

It can be proven in a simple way by using basic theorems of the probability, as seen in \cref{eq:bayes_proof}.

\begin{equation}
\label{eq:bayes_proof}
\begin{aligned}
	P \left( H \cap E \right)
	&= P \left( H \mid E \right)P \left( E \right) \\
	&= P \left( E \mid H \right)P \left( H \right) \\
	P \left( H \mid E \right) P \left( E \right) &= P \left( E \mid H \right) P \left( H \right) \\
	P \left( H \mid E \right) &= \frac{P \left( E \mid H \right) P \left( H \right)}{P \left( E \right)}
\end{aligned}
\end{equation}

Most of the equations presented in this section deal with continuous probabilities, which by definition must integrate to 1~\cite{kolmogrov1956}. Therefore, the theorem is usually used in the version presented in \cref{eq:bayes_propto}, which defines the proportionality of the \emph{Posterior}.

\begin{equation}
\label{eq:bayes_propto}
	P \left( H \mid E \right) \propto P \left( E \mid H \right) \cdot P \left( H \right)
\end{equation}

\begin{figure}
\centering
\includegraphics[width=.7\textwidth]{figures/Bayes_Theorem.png}
\caption{Graphical visualization of \emph{Bayes Theorem} between two probabilities $A$ and $B$ by the superposition of two decision trees starting in hypothesis space $\Omega$.}
\label{fig:Bayes_Theorem}
\end{figure}

\subsection{Conjugate Priors}
\label{subsec:conjugate}

For a single problem there may be many different possible \emph{Prior Probabilities}, which can be defined depending on the approach taken on defining the model to represent different measures of knowledge and certainty about the data\footnotemark{}. In particular, if the prior is less informative then the posterior is more likely to be determined by the data.

\footnotetext{An extreme case is the \emph{Jeffreys Prior}, used to express total ignorance about the data~\cite{jeffreys453}.}

A simple way to choose a correct prior is using a \emph{Conjugate Prior}. A distribution $P \left( H \right)$ is \emph{Conjugate} to $P \left( H \mid E \right)$ if multiplying the two distributions together and normalizing the results in another distribution has the same form as $P \left( H \right)$.

The \emph{Conjugate Prior} has some philosophical significance in the context of \emph{Bayesian Estimator}. In the practical case, the \emph{Prior Probability} contains more or less information compared to the \emph{Posterior Probability} depending on the amount of data seen. In particular, if the experiment has seen little data, a single datapoint can influence your beliefs significantly. On the other hand, if the experiment has a lot of data, then one single extra datapoint shouldn't influence them as much~\cite{gelman2003}.

\section{The Beta Distribution}
\label{subsec:beta}

The \emph{Beta Distribution} is a family of continuous probability distributions defined in the interval $\left[ 0, 1 \right]$ which is parametrized by two shape parameters, $\alpha$ and $\beta$.

The distribution can be used to model the behaviour of \emph{Random Variables} limited to intervals of a finite length. It is often used as a statistical function to model unknown data from a known sample, such as allele frequencies in population genetics~\cite{Balding1995}, Malaysian sunshine data~\cite{Sulaiman1999573}, and heterogeneity in the probability of HIV transmission~\cite{SIM:SIM4780080110}.

In the context of \emph{Bayesian Inference}, the \emph{Beta Distribution} is the \emph{Conjugate Prior} of the \emph{Binomial Distribution}, which allows us to describe initial knowledge concerning probability of success of a single bi-variate distribution. In layman terms, this allows us to know what is the distribution of the continuous $p$ parameter of a binomial distribution for which we have $\alpha$ positive and $\beta$ negative samples.

\subsection{Probability Density Function}

Given a variable $0 \leq x \leq 1$, which represents the unknown probability of having a \emph{Positive Sample} from the distribution, and the shape parameters $\alpha > 0$ and $\beta > 0$, the \emph{Probability Density Function} of the beta distribution can be described as in \cref{eq:beta_pdf}, where $\kappa$ represents some constant.

\begin{equation}
\label{eq:beta_pdf}
\begin{aligned}
f\left(x; \alpha, \beta\right) &= \kappa \cdot x^{\alpha - 1} {\left( 1 - x \right)}^{\beta - 1} \\
&= \dsfrac{x^{\alpha - 1} {\displaystyle \left( 1 - x \right)}^{\beta - 1}}{\int^1_0 {u^{\alpha - 1} {\left( 1 - u \right)}^{\beta - 1} du}} \\
&= \dsfrac{\Gamma \left( \alpha + \beta \right)}{\Gamma \left( \alpha \right) \Gamma \left( \beta \right)} \cdot x^{\alpha - 1} {\left( 1 - x\right)}^{\beta - 1} \\
&= \dsfrac{1}{\Beta \left(\alpha, \beta\right)} \cdot x^{\alpha - 1} {\left(1 - x\right)}^{\beta - 1}
\end{aligned}
\end{equation}

\begin{equation}
\label{eq:beta_function}
\Beta\left(\alpha, \beta\right) = \frac{\Gamma\left(\alpha + \beta\right)}{\Gamma\left(\alpha\right) \Gamma\left(\beta\right)}
\end{equation}

\Cref{eq:beta_function}, describes the \emph{Beta Function}, which is related to the \emph{Gamma Function} and describes a similar pattern~\cite{thegammafunction}.

Regarding this thesis, the \emph{Beta Distribution} will be used to model a real life problem in \cref{sec:inference_methodology}. In this problem, both $\alpha \in \mathbb{N}$ and $\beta \in \mathbb{N}$, so the \emph{Beta Function} can be simplified using the identity $\left( x - 1 \right)! = \Gamma \left( x \right)$ as shown in \cref{eq:beta_int}.

\begin{equation}
\label{eq:beta_int}
\Beta(\alpha, \beta) = \frac{(\alpha + \beta - 1)!}{(\alpha - 1)! \cdot (\beta - 1)!}
\end{equation}

Additionally, the \emph{Beta Function} can be generalized into the \emph{Incomplete Beta Function} for some parameter $x$ as in \cref{eq:incomplete_beta}. This function is, confusingly, also represented with the Greek letter $\Beta$; to ease comprehension this thesis will refer to it as $\Betainc$.

\begin{equation}
\label{eq:incomplete_beta}
\Betainc(x; \alpha, \beta) = \int_0^x {t^{\alpha - 1} {(1 - t)}^{\beta - 1} dt}
\end{equation}

As we get more data from the sampling, the \emph{Beta distribution} turns more concentrated towards the actual $\theta$ and its shapes resembles more a normal curve, as can be seen in \cref{fig:betagraph}. This represents the increased certainty which comes from the acquired knowledge of the problem.

\begin{figure}
\centering
\includegraphicsmaybe{figures/beta.png}
\caption{Beta distribution with different parameters}
\label{fig:betagraph}
\end{figure}

\subsection{Cumulative Distribution Function}

The \emph{Cumulative Distribution Function} of the \emph{Beta Distribution} is defined in \cref{eq:beta_cdf_formula}.

\begin{gather}
\begin{gathered}
\label{eq:beta_cdf}
X \sim \Betadist \left( \alpha, \beta \right) \\
F \left( x; \alpha, \beta \right) = P \left( X \leq x \right)
\end{gathered} \\
\label{eq:beta_cdf_formula}
\begin{aligned}
F \left( x; \alpha, \beta \right)  &= \int_0^x f \left( t; \alpha, \beta \right) dt \\
&= \int_0^x {\frac{1}{\Beta \left( \alpha, \beta \right)} t^{\alpha - 1} {\left( 1 - t \right)}^{\beta - 1} dt} \\
&= \frac{1}{\Beta \left( \alpha, \beta \right)} \cdot \int_0^x {t^{\alpha - 1} {\left( 1 - t \right)}^{\beta - 1} dt} \\
&= \frac{\Betainc \left( x; \alpha, \beta \right)}{\Beta \left( \alpha, \beta \right)}
\end{aligned}
\end{gather}

$F$ is also known as the \emph{Regularized Incomplete Beta Function}, represented as $I_x(\alpha, \beta)$. This function is related to the \emph{Cumulative Distribution Function} of the \emph{Binomial Distribution}, as shown in \cref{eq:incomplete_beta_binomial}.

\begin{equation}
\label{eq:incomplete_beta_binomial}
\begin{gathered}
X \sim \Binom \left( n, p \right)  \\
P \left( X \leq k \right)  = I_{1 - p} \left( n - k, k + 1 \right)
\end{gathered}
\end{equation}

\subsection{Inverse Cumulative Distribution Function}
\label{subsec:beta_ppf}

The problems solved in this thesis require the use of the \emph{Inverse Cumulative Distribution Function} (also known as the \emph{Quantile Function} or the \emph{Percent-Point Function}) of the \emph{Beta Distribution}, which returns a value such $x$ that meets the expression in \cref{eq:beta_cdf} is equal to some value $p$. It can also be expressed as in \cref{eq:quantile_function}.

\begin{equation}
\label{eq:quantile_function}
Q \left( p \right)  = \inf \left\{ x \in \mathbb{R} \mid p \leq F \left( x \right) \right\}
\end{equation}

Like with the \emph{Cumulative Distribution Function}, there is no closed form formula for expressing its inverse~\cite{kippingexoplanets2013}. However, there are fast and accurate ways of computing it using either \emph{Interval~Halving} or \emph{Newton's~Method}, such as the \texttt{incbi} implementation in the \emph{Cephes} library~\cite{cephes} which is use in this thesis via a wrapper from \texttt{sklearn}, as explained in \cref{subsec:experimental_environment}.

\subsection{The Beta-Binomial Model}
\label{subsec:betabin}

In the \emph{Beta-Binomial Model} compromises a family of discrete probability distributions similar to the \emph{Binomial Distribution}, with the important difference that, instead of each trial having a constant probability of success, that probability is random and follows the \emph{Beta Distribution}~\cite{schervish1996statistics}.

Given a binary experiment which is run $n$ times, and the probability of success of any of those experiment is some constant $\theta$, the \emph{Probability Distribution} of the amount of successes $k$ can be modelled with a \emph{Binomial Distribution}, as shown in \cref{eq:betabin_binomial}.

\begin{equation}
\label{eq:betabin_binomial}
\begin{gathered}
	k \mid n, \theta \sim \Binomial \left( \theta, n \right) \\
	P \left( k = x \mid n, \theta \right) = \binom{n}{k} \cdot \theta^k {\left( 1 - \theta \right)}^{n - k}
\end{gathered}
\end{equation}

$\theta$ is a random continuous probability distribution, which is defined using the \emph{Beta Distribution} in \cref{eq:betabin_beta}.

\begin{equation}
\label{eq:betabin_beta}
\begin{gathered}
	\theta \mid \alpha, \beta \sim \Beta \left( \alpha, \beta \right) \\
	P \left( \theta \mid \alpha, \beta \right) = \frac{1}{\Beta \left( \alpha, \beta \right)} \cdot \theta^{\alpha - 1} {\left( 1 - \theta \right)}^{\beta - 1}
\end{gathered}
\end{equation}

Once the binary experiment is run, the model has additional information which may change the distribution of $\theta$. This can be modelled as a \emph{Posterior Distribution} using \emph{Bayes Theorem}~\cite{betabinomialcmu}.

\begin{equation}
\label{eq:betabin_bayes}
\begin{aligned}
	P \left( \theta \mid n, k, \alpha, \beta \right)
	&= \frac{P \left( k \mid n, \theta \right) P \left( \theta \mid n, \alpha, \beta \right)}{P \left( k \mid n, \alpha, \beta \right)} \\
	&\propto P \left( k \mid n, \theta \right) P \left( \theta \mid n, \alpha, \beta \right) \\
	&= P \left( k \mid n, \theta \right) P \left( \theta \mid \alpha, \beta \right) \\[1em]
	P \left( \theta \mid n, k, \alpha, \beta \right)
	&= \binom{n}{k} \theta^k {\left( 1 - \theta \right)}^{n - k} \cdot \frac{1}{\Beta \left( \alpha, \beta \right) } \theta^{\alpha - 1} {\left( 1 - \theta \right)}^{\beta - 1} \\
	&\propto \theta^k {\left( 1 - \theta \right)}^{n - k} \cdot \theta^{\alpha - 1} {\left( 1 - \theta \right)}^{\beta - 1} \\
	&= \theta^{k + \alpha - 1} {\left( 1 - \theta \right)}^{n - k + \beta - 1}
\end{aligned}
\end{equation}

This is exactly the same function as the one in \cref{eq:betabin_beta}. That is, the \emph{Posterior Distribution} of this model is also a \emph{Beta Distribution}.

\begin{equation}
\label{eq:betabin_posteriorbeta}
	\theta \mid k, n, \alpha, \beta \sim \Betadist \left( \alpha + k, \beta + n - k \right)
\end{equation}

This way it's possible to see that the \emph{Beta Distribution} has the properties of a \emph{Conjugate Prior Distribution} seen in \cref{subsec:conjugate} to the \emph{Binomial Likelihood}. This makes it extremely desirable for \emph{Bayesian Analysis}, and for this reason it's used as the main model of this thesis. This is seen in more detail \cref{subsec:modelling_users}.

\section{Machine Learning Validation Metrics}
\label{subsec:mlmetrics}

In the following subsections we present the outline of several supervised machine learning algorithms which are used to compare the Bayesian method to a more realistic baseline. First, we'll present several ways to validate the different algorithms when applied to the data. In the following section, we'll present many of the algorithms used for comparison.

Given a set of features $Z$, all of which belong to members of a population which belong to a certain category, and a random subset of those features $X \subseteq Z$ whose category $y$ is known, the models should be trained with $X$ and $y$ in order to correctly predict the values corresponding to all the features in $Z$. Since those values are unknown validation of the output is impossible; therefore, we validate the model using the known values in $X$ and $y$.

There are many metrics that can be used to measure the performance of a classifier or a predictor~\cite{binaryevaluation}; different fields have different preferences due to different goals. In this section, we present many metrics to evaluate different results that are commonly used in the area of mobile phone data analysis~\cite{oskarsdottir2016}.

\subsection{Classification of individual results}

Once we define out classifier $g$ and run it against a matrix of features, we get a predicted result $\ypred$ which, when compared to the actual result $\ytrue = y$, can be classified as the one in \cref{tab:confusion}.

\begin{table}
\begin{tabularx}{\textwidth}{| c | X | X X |}
\hline

& & \multicolumn{2}{c|}{\textbf{Predicted Condition}} \\
& Total Population &
\makecell{Condition Positive} &
\makecell{Condition Negative} \\ \hline

\multirow{2}{5em}{\textbf{True Condition}} &
Condition Positive &
\cellcolor{OrangeRed} \makecell{\textbf{True Positive}} &
\cellcolor{CadetBlue} \makecell{\textbf{False Negative} \\ (Type II error)} \\


& Condition Negative &
\cellcolor{CadetBlue} \makecell{\textbf{False Positive} \\ (Type I Error)} &
\cellcolor{OrangeRed} \makecell{\textbf{True Negative}} \\ \hline

\end{tabularx}
\caption[caption]{Confusion Table, showing different classifications of an individual prediction. True and False Positives ($\TP$/$\FP$) refer to the number of predicted positives that were correct/incorrect, and similarly for True and False Negatives ($\TN$/$\FN$).}
\label{tab:confusion}
\end{table}

Additionally, this table can be easily seen in a graphical way in \cref{fig:truefalsenegativepositive}.

\begin{figure}
\centering
\includegraphicsmaybe{figures/TrueFalseNegativePositive.png}
\caption{Visual explanation of \emph{Precision} and \emph{Recall}}
\label{fig:truefalsenegativepositive}
\end{figure}

\subsection{Precision and Recall}
\label{subsec:precisionrecall}
\emph{Precision} denotes the proportion of predicted positive cases that are correctly real positive. Trying to maximize this would allow us to adjust a particular predictor so that the majority of the predicted cases are actually positive. Conversely, \emph{recall} is the proportion of real positive cases that are correctly predicted positive, and maximizing it would allow us to adjust a predictor so that the majority of positive cases are predicted.

\begin{equation}
\begin{split}
\Precision = \TPA &= \frac{\TP}{\TP + \FP} \\
\Recall = \TPR &= \frac{\TP}{\TP + \FN}
\end{split}
\label{precisionrecall}
\end{equation}

These two measures and their combinations focus only on the positive examples and predictions, although between them they capture some information about the rates and kind of errors made~\cite{binaryevaluation}. While the \emph{recall} has been shown to have a major weight in working with machine translation~\cite{fraser2007}, they aren't particularly useful to use alone since they don't take into account many factors of the prediction~\cite{binaryevaluation}.

\subsection{Inverse~Precision and Inverse~Recall}

As a corollary of the previous metrics, we can add metrics that measure the proportion of real negative cases that are correctly predicted negative, referred as the \emph{Inverse~Recall}, and the proportion of predicted negatives that are real negatives, referred as the \emph{Inverse~Precision}\cite{binaryevaluation}. We can see that these are equivalent to finding the \emph{Precision} and \emph{Recall} of the negative category.

\begin{equation}
\begin{split}
\InvPrecision = \TNR &= \frac{\TN}{\FP + \TN} \\
\InvRecall = \TNA &= \frac{\TN}{\FN + \TN}
\end{split}
\label{negativeprecisionrecall}
\end{equation}

\subsection{Accuracy}
\label{subsec:accuracy}
The \emph{accuracy}, commonly referred in the context of binary classifiers as \textbf{Rand~Accuracy}\cite{powers15}, is used as a statistical measure of how well a binary classification test identifies or excludes a condition. Unlike the \emph{precision}, it takes into account the negatives, and it's expressible~\cite{binaryevaluation} both as a weighted average of \emph{precision} and inverse \emph{precision} or \emph{recall} and \emph{inverse recall}.

\begin{equation}
\Accuracy = \frac{\TP + \TN}{N}
\label{accuracy}
\end{equation}

This can be more simply expressed using the weighted average of either the \emph{Precision} and \emph{Inverse~Precision} or the \emph{Recall} and the \emph{Inverse~Recall}.

\begin{equation}
\begin{split}
\Accuracy &= \left(\TP + \TN\right) \cdot \TPR + \left(\FP + \TN\right) \cdot \TNR \\
&= \left(\TP + \FP\right) \cdot \TPA + \left(\FN + \TN\right) \cdot \TNA
\end{split}
\label{accuracy2}
\end{equation}

\subsection{ROC Curve}

A \emph{Receiver Operating Characterising} graph is a technique for visualizing, organizing, and selecting classifiers based on their performance~\cite{fawcett2005}. The curve is created by plotting the \emph{True Positive Rate} against the \emph{False Positive Rate} at various threshold settings.

This allows to compare different classifiers before having to select a particular threshold value for them. In particular, a random classifier will score near the positive diagonal ($\FPR = \TPR$), while a perfect classifier will score in the top left hand corner ($\FPR = 1, \TPR = 0$) and a worst case classifier will score in the bottom right hand corner\footnote{Note that, for any binary classifier, it's trivial to transpose the entire ROC curve (or a part of it) to the other part of the diagonal; therefore the worst ``realistic'' case is the random one}\cite{binaryevaluation}.

\begin{figure}
\centering
\includegraphics[width=.50\textwidth]{figures/ROC_example.png}
\caption{A \emph{ROC Curve}, where the \emph{Area Under the Curve} is marked. This particular graph comes from data used in early experiments to finding the socioeconomic index of a person, which is explained with more detail in \cref{sec:inference_methodology}.}
\label{fig:roc}
\end{figure}

\subsection{Area Under the Curve}
\label{subsec:auc}
The \emph{ROC Curve} allows us to compare classifiers and choose the one which is closer to optimal in some sense. While there are many possible parametrizations, the most common is to minimize the \emph{Area Under the Curve}, which is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one~\cite{fawcett2005}. This can be formulated as shown in \cref{eq:auc}.

\begin{equation}
\begin{aligned}
\AUC &= P\left(X_1 > X_0\right) \\
&= \int_0^1 \TPR \left( t \right) \FPR' \left( t \right) dt
\end{aligned}
\label{eq:auc}
\end{equation}

\subsection{F-measure}
\label{subsec:fmeasure}
The \emph{F-measure} is another measure of a tests accuracy. It considers both the \emph{Precision} and the \emph{Recall} of the test to compute the score. It can be considered the weighted average of both values for some weight $\beta$, where $F_\beta$ reaches the best score 1 when both precision and recall are 1.

\begin{equation}
\begin{split}
F_\beta &= \left( 1 + \beta^2 \right) \cdot \frac{\TPA \cdot \TPR}{\left( \beta^2 \cdot \TPA \right) + \TPR} \\
&= \frac{\left( 1 + \beta^2 \right) \cdot \TP}{\left( 1 + \beta^2 \right) \cdot \TP + \beta^2 \cdot \FN + \FP}
\end{split}
\end{equation}

The most commonly used \emph{F-measure}, $F_1$, measures the \emph{Precision} and \emph{Recall} is that harmonic mean of the \emph{Precision} and \emph{Recall}. In particular, for an \emph{F-measure} with $\beta > 1$ weights Recall higher than Precision, while with $\beta < 1$ weights Precision higher than Recall.

\input{supervisedml}
