\section{Comparison with Other Inference Methods}
\label{sec:comparison}

In the following section, we compare the results of the Bayesian method with other classifiers.

\begin{figure}
	\begin{tabularx}{\textwidth}{>{\bfseries}X c c c c c c}
		\toprule
		\textbf{Classifier} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{AUC} & \textbf{$F_1$}-\textbf{score} & \textbf{$F_4$}-\textbf{score} \\
		\midrule
		Método Bayesiano & 0 & 0 & 0 & 0 & 0 & 0 \\
		\midrule
		Random Selection & 0.500 & 0.510 & 0.501 & 0.500 & 0.529 & 0.504 \\
		Majority Voting & 0 & 0 & 0 & 0 & 0 & 0 \\
		\midrule
		Naïve Bayes & 0.569 & 0.550 & 0.711 & 0.550 & 0.649 & 0.703 \\
		K Nearest Neighbors\footnote{Selecting $K = 9$} & 0.551 & 0.589 & 0.666 & 0.55 & 0.625 & 0.661 \\
		SVM with RBF kernel\footnote{Selecting $C = 100$} & 0.559 & 0.561 & 0.947 & 0.571 & 0.705 & 0.910 \\
		Logistic Regression\footnote{Selecting $C = 0.01$} & 0.563 & 0.563 & 0.991 & 0.569 & 0.718 & 0.949 \\
		Stochastic Gradient Descent & 0.557 & 0.575 & 0.861 & 0.516 & 0.679 & 0.833 \\
		Random Forest & 0.570 & 0.571 & 0.638 & 0.668 & 0.606 & 0.673 \\
		\midrule
		Categorized LR & 0 & 0 & 0 & 0 & 0 & 0 \\
		Count Link Model & 0 & 0 & 0 & 0 & 0 & 0 \\
		\bottomrule
	\end{tabularx}
\end{figure}

\subsection{Random Selection}

For completeness sake we created a random classifier for the socioeconomic category of each user.

We applied two other inference methods to the same data and compared their accuracies to our Bayesian model.

\begin{itemize}
	\item \textbf{Random selection} which chooses randomly the category for each user.
	\item \textbf{Majority voting} which decides whether a user is in the high or low income category depending on the category of the majority of its contacts. In case of a tie, the category is chosen randomly.
\end{itemize}

The \emph{accuracy} of the first method is as expected \num{0.5}, while the \emph{accuracy} for majority voting is \num{0.66}.
With the Bayesian method we obtain an \emph{accuracy} of \num{0.71}.

\subsection{Graph Sampling}

The set $B$ is randomly sampled into two disjoint subsets, $T$ and $S$, such that $T \cup S = B$ and $T \cap S = \varnothing$. Additonally, $\left| T \right| = \sfrac{4}{5} \cdot \left| B \right|$ and $\left| S \right| = \sfrac{1}{5} \cdot \left| B \right|$. We use $T$ as the \emph{Training Set} of the data, while $S$ is considered the \emph{Testing Set}. This way, we can be sure of not having overfitting issues when applying \emph{Machine Learning} methods to the data.

\subsection{User Data}
\label{subsec:user_data}

As explained in Section~\ref{subsec:mobiledatasource}, the set $P$ contains \emph{Call Detail Records}. Each element $p \in P$ contains the caller and the callee $\left< p_o, p_d \right>$ and call data (including the call duration $p_s$). Additionally, the set $S$ contains \emph{SMS Records}, which for each element $s \in S$ contain origin and destination data $\left< s_o, s_d \right>$.

For each element of the set of users that belong to the telco $u \in U \subseteq P_o \cup P_d \cup S_o \cup S_d$, it's possible to define the following features.

\begin{equation}
\label{eq:calls}
\begin{split}
\operatorname{incalls}_u  &= \left| \left\{ p \in P \mid p_d = u \right\} \right| \\
\operatorname{outcalls}_u &= \left| \left\{ p \in P \mid p_o = u \right\} \right|
\end{split}
\end{equation}

\begin{equation}
\label{eq:time}
\begin{split}
\operatorname{intime}_u  &= \sum_{\substack{p \in P \\ p_d = u}} \, p_s \\
\operatorname{outtime}_u &= \sum_{\substack{p \in P \\ p_o = u}} \, p_s
\end{split}
\end{equation}

\begin{equation}
\label{eq:sms}
\begin{split}
\operatorname{insms}_u  &= \left| \left\{ s \in S \mid s_d = u \right\} \right| \\
\operatorname{outsms}_u &= \left| \left\{ s \in S \mid s_o = u \right\} \right|
\end{split}
\end{equation}

\begin{equation}
\label{eq:contacts}
\begin{split}
\operatorname{incontacts}_u  &= \left| \left\{ p_o \mid p \in P \and p_d = u \right\} \cup \left\{ s_o \mid s \in S \and s_d = u \right\} \right| \\
\operatorname{outcontacts}_u &= \left| \left\{ p_d \mid p \in P \and p_o = u \right\} \cup \left\{ s_d \mid s \in S \and s_o = u \right\} \right|
\end{split}
\end{equation}

In particular, Equation~\ref{eq:calls} refers to the amount of in-calls and out-calls each user has, Equation~\ref{eq:time} to the total time in incoming calls and outgoing calls, Equation~\ref{eq:sms} the amount of incoming and outgoing SMS, and Equation~\ref{eq:contacts} to the total amount of different users where either a call of an SMS has been made or received. These last two features correspond to the \emph{In-Degree} and \emph{Out-Degree} of the node in the graph.

These features will be referred as the \emph{User Data} of user $u$.

\subsection{Higher Order User Data}
\label{subsec:higherorderuserdata}

Where \emph{User Data} contains data directly about the neighbours of each user, we can define \emph{User Data of Order $1$}, as the user data variables about the edges of the neighbours of each user $u$ where $u$ isn't any of the endpoints. In the case of cumulative data (calls, time, and SMS), this is equal to the sum of the \emph{User Data} of the neighbours of $u$ minus the \emph{User Data} os $u$ (since we aren't counting ``inner'' edges). This isn't true in the case of the contacts, since two neighbours of $u$ may have a contact in common, which should be counted only once.

Additionally, for any $n \in \mathbb{N}$, we can inductively define the \emph{User Data of Order $n$} as the user data of the nodes at distance $n$ of a certain node.

\subsection{Categorical User Data}
\label{subsec:categoricaluserdata}

Another possible featureset consists of using of separating the data of the neighbourhood of each user $u \in U$ into two disjoint groups, $L_u$ and $K_u$, which contain the neighours of $u$ in the low and high categories of income respectively\footnotemark{}.

\footnotetext{Note that, since not all users have banking information, there may be nodes in the neighbourhood of $u$ which don't belong to either $L_u$ or $K_u$.}

\begin{equation}
\begin{split}
	L_u &\subseteq H_1 \cap \left( \left\{ p_o \mid p \in P \and p_d = u \right\} \cup \left\{ p_d \mid p \in P \and p_d = u \right\} \right) \\
	K_u &\subseteq H_2 \cap \left( \left\{ p_o \mid p \in P \and p_d = u \right\} \cup \left\{ p_d \mid p \in P \and p_d = u \right\} \right) \\
\end{split}
\end{equation}

Having these groups it's possible to define a set of features similar to the one in Section~\ref{subsec:user_data}, where each feature is separated by the category of the neighbour. Equation~\ref{eq:matcatuserdata} contains the possible forms of the new features, while Equation~\ref{eq:categoricaluserdata} contains the way to calculate some of them. The formula for the rest of the features comes trivially.

\begin{equation}
\label{eq:matcatuserdata}
	\begin{Bmatrix} in \\ out \end{Bmatrix}
	\times
	\begin{Bmatrix} calls \\ time \\ sms \\ contacts \end{Bmatrix}
	\times
	\begin{Bmatrix} low \\ high \end{Bmatrix}
\end{equation}

\begin{equation}
\label{eq:categoricaluserdata}
\begin{split}
	\operatorname{incallslow}_u &= \left| \left\{ p \in P \mid p_d = u \and \mathbf{p_o \in H_1} \right\} \right| \\
	\operatorname{outtimelow}_u &= \sum_{\substack{p \in P \\ p_o = u \\ \mathbf{p_d \in H_1}}} \, p_s \\
	\operatorname{outcontactshigh}_u &= \left| \mathbf{H_2 \, \cap} \, \left( \left\{ p_d \mid p \in P \and p_o = u \right\} \cup \left\{ s_d \mid s \in S \and s_o = u \right\} \right) \right|
\end{split}
\end{equation}

There are two distinct analyses done with \emph{Categorical User Data}: one with all the nodes in $T$, unambiguously called the ``outer graph'', and one that only contains the nodes in $T$ which are adjacent to at least one other node in $T$, unambiguously called the ``inner graph''. The latter should give a better or equal result, since the rest of the nodes contains no information in this category.

The ``outer graph'' contains \todo{add amount of nodes here}, while the ``inner graph'' contains only \todo{same here}.

\subsection{Validation Metrics}
\label{subsec:validationmetrics}
There are several validation metrics used for each method.

\begin{description}
	\item[Accuracy] as described in Subsection~\ref{subsec:accuracy}, which measures the general performance of this method.
	\item[Precision] as described in Subsection~\ref{subsec:precisionrecall}, which measures the performance regarding the positive instances found by this method.
	\item[Recall] as described in Subsection~\ref{subsec:precisionrecall}, which measures the performance regarding the positive instances in the dataset.
	\item[Area Under the Curve] as described in Subsection~\ref{subsec:auc}, which measures the general performance disregarding which threshold is used.
	\item[$\mathbf{F_1}$ Score] as described in Subsection~\ref{subsec:fmeasure} which is generalized score balancing Precision and Recall.
	\item[$\mathbf{F_4}$ Score] as described in Subsection~\ref{subsec:fmeasure}, which gives more weight to the Recall. This is usually wanted since the ultimate practical objective of this study is to find wealthier people, even if the result has low Precision.
	\item[Time] can be used to break ties between similar models.
\end{description}

\subsection{Feature Extraction}
\label{subsec:featureextraction}
Using the previous graph, we can create features separated into different levels.

\begin{enumerate}
	\item[0] \emph{Local Features} as described in Section~\ref{subsec:user_data}.
	\item[0.5] \emph{Classified Local Features} as described in Section~\ref{subsec:categoricaluserdata} (using only the adjacency information of the training set $T$), joined with the data on the previous item. There are two separate sets of sampels used for experiments on this level.
	\begin{description}
		\item[Outer Nodes] which contain all samples in $S$.
		\item[Innter Nodes] which only contain samples in the testing set $S$ which have at least a neighbour in the training set $T$.
	\end{description}
	\item[1] \emph{Neighbour Features}, as described in Section~\ref{subsec:higherorderuserdata} for \emph{User Data of Order 1}, joined with data on \textbf{Level 0}.
	\item[1.5] \emph{Classified Neighbouring Features}, which combine the feature extraction methods seen in Section~\ref{subsec:categoricaluserdata} and Section~\ref{subsec:higherorderuserdata}, and separate the accumulation of the \emph{User Data} of a node's neighbours along categorical features. This data is also joined with all previous levels, and discriminated between sets of \emph{Outer Nodes} and \emph{Inner Nodes}
	\item[$\geq 2$] The method described in Section~\ref{subsec:higherorderuserdata}, with or without classification by the type of the other endpoint of the link. In this section, we'll prove that the accuracy of the methods before this one are similar enough to the ones in this level so that sacrificing speed is not worth the new features.
\end{enumerate}

\begin{table}
\centering
\begin{tabular}{>{\bfseries}l c c c c c c c}
\toprule
\textbf{Level} & 0 & \multicolumn{2}{c}{0.5} & 1 & \multicolumn{2}{c}{1.5} & 2 \\
\cmidrule(lr){3-4} \cmidrule(lr){6-7}
\textbf{Dataset} &   & inner     &    outer    &   & inner     &    outer    &   \\
\midrule
Features &\num{1234567}&\num{1234567}&\num{1234567}&\num{1234567}&\num{1234567}&\num{1234567}&\num{1234567}\\
Samples  &\num{1234567}&\num{1234567}&\num{1234567}&\num{1234567}&\num{1234567}&\num{1234567}&\num{1234567}\\
\bottomrule
\end{tabular}
\caption{Size of the datasets used for testing for each feature extraction method}
\label{tab:datasettable}
\todo{Change placeholders for actual numbers}
\end{table}

These datasets contain differing numbers of features and samples, as described in Table~\ref{tab:datasettable}.

\subsection{Results}

Applying the features from Section~\ref{subsec:featureextraction} to the \emph{Random Forest} model described in Section~\ref{subsec:randomforest} and the \emph{Logistic Regression} model described in Section~\ref{subsec:logisticregression}. Prior to applying each model, a \emph{Grid Search} was made with the parameter $C$ in the case of the \emph{Logistic Regression} as shown by Equation~\ref{eq:gridsearch}, and the \emph{Criterion} used in the \emph{Random Forest}, and the hyperparameter which results in the most \emph{Accuracy} after 5-fold cross validation was used.

\begin{equation}
\label{eq:gridsearch}
\begin{split}
C &\in \left\{ 0.01, 0.1, 1, 10, 100 \right\} \\
\operatorname{Criterion} &\in \left\{ \text{Gini}, \text{Entropy} \right\}
\end{split}
\end{equation}

The results of the \emph{Grid Search} are presented in Table~\ref{tab:gridsearch}, while the different metrics of the result are presented in Table~\ref{tab:comparison}.

\begin{table}
\centering
\begin{tabular}{>{\bfseries}l l @{\hskip 2em} r r}
\toprule
Level & Dataset & $C$ (LR) & Criterion (RF) \\
\midrule

0 & & \num{10} & Entropy \\ [1.5ex]

\multirow{2}{*}{0.5} & Outer & \num{0.01} & Gini \\
& Inner & \num{1} & Gini \\ [1.5ex]

1 & & \num{100} & Entropy \\ [1.5ex]

\multirow{2}{*}{1.5} & Outer & \num{100} & Entropy \\
& Inner & \num{100} & Entropy \\
\bottomrule

\end{tabular}
\caption{Best hyperparameters for each group of features in each model used}
\label{tab:gridsearch}
\end{table}

\begin{table}
\begin{tabular*}{\textwidth}{>{\bfseries}l l l @{\extracolsep{\fill}} r r r r r r r}
\toprule
Level & Dataset & Method & Accuracy & Precision & Recall & AUC & F\textsubscript{1}-score & F\textsubscript{4}-score & Time \\
\midrule

\multirow{2}{*}{0}
& & LR & \num{0.541} & \num{0.580} & \num{0.299} & \num{0.541} & \num{0.395} & \num{0.308} & \SI{2.647}{\second} \\
& & RF & \num{0.541} & \num{0.542} & \num{0.528} & \num{0.541} & \num{0.535} & \num{0.528} & \SI{11.396}{\second} \\
\midrule

\multirow{4}{*}{0.5}
& \multirow{2}{*}{Outer} & LR &\num{0.570} & \num{0.749} & \num{0.212} & \num{0.570} & \num{0.330} & \num{0.221} & \SI{3.727}{\second} \\
& & RF &\num{0.567} & \num{0.572} & \num{0.533} & \num{0.567} & \num{0.552} & \num{0.535} & \SI{8.528}{\second} \\
\cmidrule{2-10}
& \multirow{2}{*}{Inner} & LR &\num{0.720} & \num{0.747} & \num{0.842} & \num{0.675} & \num{0.792} & \num{0.836} & \SI{1.005}{\second} \\
& & RF &\num{0.700} & \num{0.738} & \num{0.817} & \num{0.658} & \num{0.775} & \num{0.812} & \SI{2.146}{\second} \\
\midrule

\multirow{2}{*}{1}
& & LR & \num{0.552} & \num{0.597} & \num{0.326} & \num{0.553} & \num{0.422} & \num{0.335} & \SI{5.255}{\second} \\
& & RF & \num{0.572} & \num{0.580} & \num{0.527} & \num{0.572} & \num{0.552} & \num{0.530} & \SI{22.523}{\second} \\
\midrule

\multirow{4}{*}{1.5}
& \multirow{2}{*}{Outer} & LR & \num{0.598} & \num{0.726} & \num{0.358} & \num{0.606} & \num{0.479} & \num{0.369} & \SI{22.851}{\second} \\
& & RF & \num{0.723} & \num{0.747} & \num{0.852} & \num{0.675} & \num{0.796} & \num{0.845} & \SI{4.780}{\second} \\
\cmidrule{2-10}
& \multirow{2}{*}{Inner} & LR & \num{0.643} & \num{0.668} & \num{0.617} & \num{0.644} & \num{0.642} & \num{0.620} & \SI{21.498}{\second} \\
& & RF & \num{0.735} & \num{0.766} & \num{0.838} & \num{0.697} & \num{0.800} & \num{0.834} & \SI{6.706}{\second} \\
\midrule

\multirow{2}{*}{2}
& & LR & \num{0} & \num{0} & \num{0} & \num{0} & \num{0} & \num{0} & \SI{0}{\second} \\
& & RF & \num{0} & \num{0} & \num{0} & \num{0} & \num{0} & \num{0} & \SI{0}{\second} \\
\bottomrule

\end{tabular*}
\caption{Results of running dataset with different feature extraction methods}
\label{tab:comparison}
\todo{Add level $\geq 2$}
\end{table}
