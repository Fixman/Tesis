% !TEX root = tesis.tex

\chapter{Comparison with Other Inference Methods}
\label{sec:comparison}

In this chapter, we compare the results of the Bayesian method presented in \cref{sec:inference_methodology} with common machine learning methods using several feature extraction methods in the graph used for this study.
Like in the previous chapter, the idea is to know whether each user $v$ belongs to a \emph{Low Category} of income, $H_1$, or to a \emph{High Category}, $H_2$, by knowing the distribution of calls and text messages to his contacts.

These classifier creates a proper baseline for other comparisons.
These will be used in the \emph{Social Graph} $G = \left< V, E \right>$, that contains data about the communications network for every user, along with the banking data $B$ separated into training and testing sets $B_{\train}$ and $B_{\test}$, and will be used to provide either information about the users.

Unlike the method presented in the previous chapter, we can optionally forego the necessity for having at least one neighbour with known socioeconomic index for each user.
For this reason, we experiment with these methods with two possible inputs, both previously defined in \cref{subsec:inner_outer_graph}.

\begin{itemize}
	\item The \emph{Outer Graph} $\Omega$, with information about every node in the graph $G$.
	\item The \emph{Inner Graph} $\Upsilon$, which only contains information about the subset of nodes which have at least one neighbour with known \emph{Socioeconomic Index}
\end{itemize}

At the end of this chapter, in \cref{sec:comparison_results}, we present a group of tables that compare the results of these methods with the \emph{Bayesian Algorithm} described in \cref{sec:inference_methodology} along several metrics.

\section{Random Selection}
\label{subsec:random_selection}

One of the simplest methods for solving many classification problems is using random selection. This classifier simply chooses randomly to which strata each user belongs.

\begin{equation}
\label{eq:random}
\begin{aligned}
	P \left( v \in H_1 \right) &= 0.5 \\
	P \left( v \in H_2 \right) &= 0.5
\end{aligned}
\end{equation}

This produces a good baseline for comparing other inference methods.

\section{Majority Voting}
\label{subsec:majority_voting}

The method of \emph{Majority Voting} is a basic but powerful way of inferring which category a user belongs to.
It simply chooses the category of each user $v \in V$ as the most common category within its contacts.

In case of a tie (which happens often when using the \emph{Outer Graph}, as many users don't have any neighbour with a known category), the category is chosen randomly.
This approach can be formalized as in \cref{eq:majority_voting}.
Here, we use the values $\contacts^{\low}_{v}$ and $\contacts^{\high}_{v}$ defined in \cref{sec:inference_methodology}: the amount of contacts user $v$ has of either low or high socioeconomic index, respectively.

\begin{equation}
\label{eq:majority_voting}
	P \left( v \in H_1 \right) =
\begin{cases}
	0   & \text{if} \ \contacts^{\low}_{v} < \contacts^{\high}_{v} \\
	0.5 & \text{if} \ \contacts^{\low}_{v} = \contacts^{\high}_{v} \\
	1   & \text{if} \ \contacts^{\low}_{v} > \contacts^{\high}_{v}
\end{cases}
\end{equation}

\section{Methods Based in Machine Learning}
\label{subsec:methods_ml}

The following methods use commonly used supervised Machine Learning algorithms, described in \cref{subsec:supervised_machine_learning}, used with many similar \emph{Feature Extraction} methods on the \emph{Social Graph} $G$.

The initial feature extraction method, referred to as \emph{User Data}, is described in \cref{subsec:user_data} and marked as $\ego_0$, consists of accumulating the total information about the links neighboring some user $v \in V$. 
Later, as shown in \cref{subsec:higherorderuserdata}, it is possible to accumulate links from more levels of the \emph{Ego Network} to create feature sets that be used to build a better prediction of the data, marked $\ego_n$ for some level $n$.

An extra method for feature extraction is presented in \cref{subsec:categoricaluserdata}, which in addition to doing the extraction of other methods it accumulates separately edges that go to \emph{High Income} and \emph{Low Income} users.
These methodologies are marked with $\cat_n$ for some level $n$.

The features of each method are merged with the ones from the immediate predecessor methods, as shown in the graph in \cref{fig:mlrelationships}, while the amount of features in each level is described in \cref{tab:datasettable}.

\begin{figure}
\centering
\resizebox{!}{.3\textheight}{%
	\framebox{%
		\input{figures/mlrelationships.tikz}
	}
}
\caption{Relationships between the \emph{Feature Extraction} methods of \cref{subsec:methods_ml}. \textcolor{Blue}{blue} edges represent an increase in \emph{Ego Network} size, a process which is describe in \cref{subsec:higherorderuserdata}, while \textcolor{ForestGreen}{green} edges represent adding label information, which is described in \cref{subsec:categoricaluserdata}}
\label{fig:mlrelationships}
\end{figure}

\begin{table}
\centering
\begin{tabular}{>{\bfseries}l r}
\toprule
Level & Features \\
\midrule
$\ego_0$ & \num{8}  \\
$\ego_1$ & \num{16} \\
$\ego_2$ & \num{24} \\
$\cat_0$ & \num{24} \\
$\cat_1$ & \num{48} \\
$\cat_2$ & \num{72} \\
\bottomrule
\end{tabular}
\caption{Number of features used for testing each Machine Learning model on each level}
\label{tab:datasettable}
\end{table}

\subsection{User Data --- Level $\ego_0$}
\label{subsec:user_data}

The features on the \emph{Social Graph} $G = \left< V, E \right>$, which contains communications data between all the users, can be accumulated for all users in a manner similar to the one in \cref{subsec:feature_accumulation}, presented again in \cref{eq:bayesian_calls_accum_copy}.

\begin{equation}
\label{eq:bayesian_calls_accum_copy}
\begin{gathered}
\begin{aligned}
& \calls^{\low}_v = \sum_{\substack{e \in E \\ e_d = v \\ e_o \in H_1}}{e_c} + \sum_{\substack{e \in E \\ e_o = v \\ e_d \in H_1}}{e_c}
& \calls^{\high}_v = \sum_{\substack{e \in E \\ e_d = v \\ e_o \in H_2}}{e_c} + \sum_{\substack{e \in E \\ e_o = v \\ e_d \in H_2}}{e_c} \\
& \etime^{\low}_v = \sum_{\substack{e \in E \\ e_d = v \\ e_o \in H_1}}{e_t} + \sum_{\substack{e \in E \\ e_o = v \\ e_d \in H_1}}{e_t}
& \etime^{\high}_v = \sum_{\substack{e \in E \\ e_d = v \\ e_o \in H_2}}{e_t} + \sum_{\substack{e \in E \\ e_o = v \\ e_d \in H_2}}{e_t} \\
& \sms^{\low}_v = \sum_{\substack{e \in E \\ e_d = v \\ e_o \in H_1}}{e_s} + \sum_{\substack{e \in E \\ e_o = v \\ e_d \in H_1}}{e_s}
& \sms^{\high}_v = \sum_{\substack{e \in E \\ e_d = v \\ e_o \in H_2}}{e_s} + \sum_{\substack{e \in E \\ e_o = v \\ e_d \in H_2}}{e_s}
\end{aligned} \\
\begin{aligned}
	\contacts^{\low }_v &= &\left| \left\{ e \in E \mid e_o = v \land e_d \in H_1 \right\} \cup \left\{ e \in E \mid e_d = v \land e_o \in H_1 \right\} \right| \\
	\contacts^{\high }_v &= &\left| \left\{ e \in E \mid e_o = v \land e_d \in H_2 \right\} \cup \left\{ e \in E \mid e_d = v \land e_o \in H_2 \right\} \right|
\end{aligned}
\end{gathered}
\end{equation}

However, and unlike in the experiments in \cref{sec:inference_methodology}, this time we aren't constrained either by having only users which have contacts with other users with known \emph{Income Category}, nor with having to have only two features for each category which was necessary since the solution used the \emph{Beta Distribution}.

This way, it is possible to accumulate features for each user $v \in V$ as in \cref{eq:user_data}.

\begin{equation}
\label{eq:user_data}
\begin{gathered}
\begin{aligned}
\incalls_v &= \sum_{\substack{e \in E \\ e_d = v}} \calls_e &
\outcalls_v &= \sum_{\substack{e \in E \\ e_o = v}} \calls_e \\
\intime_v &= \sum_{\substack{e \in E \\ e_d = v}} \etime_e &
\outtime_v &= \sum_{\substack{e \in E \\ e_o = v}} \etime_e \\
\insms_v &= \sum_{\substack{e \in E \\ e_d = v}} \sms_e &
\outsms_v &= \sum_{\substack{e \in E \\ e_o = v}} \sms_e \\
\end{aligned} \\
\begin{aligned}
\incontacts_v &= \left| \left\{ e \in E \mid e_d = v \right\} \right| \\
\outcontacts_v &= \left| \left\{ e \in E \mid e_o = v \right\} \right|
\end{aligned}
\end{gathered}
\end{equation}

These features will be referred as the \emph{User Data} of user $v$.
There features contain information about the \emph{Neighborhood} of $\upsilon$, also referred to as the \emph{Ego Network of Distance 1}. This definition is used later in this chapter, and the nodes belonging to the \emph{Neighborhood} of $\upsilon$ can be formally defined as in \cref{eq:neighbourhood}.

\begin{equation}
\label{eq:neighbourhood}
\neigh \left( \upsilon \right) = \left\{ e_o \mid e \in E \land e_d = \upsilon \right\} \cup \left\{ e_d \mid e \in E \land e_o = \upsilon \right\}
\end{equation}

\subsection{Categorical User Data --- Level $\cat_0$}
\label{subsec:categoricaluserdata}

Given the \emph{Inner Graph} $\Upsilon$, containing the subset of users where at least one neighbour has bank information, a possible feature set consists of separating the data of the neighborhood of each user $\upsilon \in \Upsilon$ into two disjoint groups, $L_{\upsilon}$ and $K_{\upsilon}$, which contain the neighbors of $\upsilon$ in the \emph{Low Income} and \emph{High Income} categories of income respectively\footnotemark{}.

\footnotetext{Note that, since not all users have banking information, there may be nodes in the neighborhood of $\upsilon$ which don't belong to either $L_{\upsilon}$ or $K_{\upsilon}$.}

\begin{equation}
\label{eq:cud_categories}
\begin{aligned}
	L_{\upsilon} &= H_1 \cap \neigh \left( \upsilon \right) \\
	K_{\upsilon} &= H_2 \cap \neigh \left( \upsilon \right)
\end{aligned}
\end{equation}

Having defined these groups it is possible to define a set of features similar to the one in \cref{subsec:user_data}, where each feature is separated by the category of the neighbor. \Cref{eq:matcatuserdata} represents an intuitive way to define the names of the new features.

\begin{equation}
\label{eq:matcatuserdata}
	\begin{Bmatrix} \text{in} \\ \text{out} \end{Bmatrix}
	\times
	\begin{Bmatrix} \text{calls} \\ \text{time} \\ \text{sms} \\ \text{contacts} \end{Bmatrix}
	\times
	\begin{Bmatrix} \text{low} \\ \text{high} \end{Bmatrix}
\end{equation}

\Cref{eq:categoricaluserdata,eq:categoricaluserdata2} contain the way to calculate those features.
Since the number of individual features is high and the formulas are similar and repetitive, the variable $\zeta$ is defined for all the types of properties.

\begin{equation}
\label{eq:categoricaluserdata}
\begin{gathered}
	\text{For $\zeta$ being any of $\left\{ \calls, \etime, \sms \right\}$,} \\
	% \left( \forall \zeta \in \left\{ \calls, \etime, \sms \right\} \right) \\
\begin{aligned}
	\underline{\text{in}{\zeta}\text{low}}_v = \sum_{\substack{e \in E \\ e_d \in L_v \\ e_o = v}} &\zeta_e &
	\underline{\text{in}{\zeta}\text{high}}_v = \sum_{\substack{e \in E \\ e_d \in K_v \\ e_o = v}} &\zeta_e \\
	\underline{\text{out}{\zeta}\text{low}}_v = \sum_{\substack{e \in E \\ e_o \in L_v \\ e_d = v}} &\zeta_e &
	\underline{\text{out}{\zeta}\text{high}}_v = \sum_{\substack{e \in E \\ e_o \in K_v \\ e_d = v}} &\zeta_e \\
\end{aligned}
\end{gathered}
\end{equation}

\begin{equation}
\label{eq:categoricaluserdata2}
\begin{aligned}
	\incontactslow_v   &= \left| \left\{ e \in E \mid e_d = v \land e_o \in L_v \right\} \right| \\
	\incontactshigh_v  &= \left| \left\{ e \in E \mid e_d = v \land e_o \in K_v \right\} \right| \\
	\outcontactslow_v  &= \left| \left\{ e \in E \mid e_o = v \land e_d \in L_v \right\} \right| \\
	\outcontactshigh_v &= \left| \left\{ e \in E \mid e_o = v \land e_d \in K_v \right\} \right|
\end{aligned}
\end{equation}

Unlike the features in \cref{subsec:user_data}, and like the method presented in \cref{sec:inference_methodology}, the features in this section will be be different when testing between the nodes of $\Omega$ (the \emph{Outer Graph}) and $\Upsilon$ (the \emph{Inner Graph}).

\subsection{Higher Order User Data --- Level $\ego_{n > 0}$}
\label{subsec:higherorderuserdata}

The features described in \cref{subsec:user_data} correspond to the information about calls and SMS from an user $\upsilon \in \Upsilon$ towards all of its neighbors, which is described as the \emph{Ego Network of Distance 1}. However, there's no reason why this information can't be extended to other nodes at a higher distance from $\upsilon$.

If the distance between two nodes is defined using the intuitive definition presented in \cref{eq:distance}, it is possible to define the \emph{User Data of Order $n$} for any number $n \in \mathbb{N}$ as the accumulation of calls and SMS where one endpoint is on the border of the \emph{Ego Network of Order $n$} and the other one isn't. The \emph{Ego Network of Order $n$} or a certain node $\upsilon$ is the sub-graph composed of the node $\upsilon$ and all the nodes which are at at most distance $n$ of $\upsilon$.

\begin{equation}
d \left( a, b \right) =
\begin{cases}
	0 & \text{if } a = b \\
	1 + \min_{v \in \ego \left(b \right)} d \left( a, v \right) & \text{otherwise}
\end{cases}
\label{eq:distance}
\end{equation}

This method creates a set of \emph{Higher Order Features} similar to the ones in \cref{eq:user_data}, with the exception that the values of the edges summed for each node are defined on the distance instead of on the definition of the $E$ itself.
Indeed, for the \emph{Social Graph} $G = \left< V, E \right>$ we can define features with formulas similar to the ones in \cref{eq:higher_order_user_data}.

\begin{equation}
	\begin{aligned}
		\incalls^n_v = \sum_{\subalign{e \in E \\ d \left( e_o, v \right) &= n \\ d \left( e_d, v \right) &= n + 1 }} \calls_e &
		\hfill &
		\outcalls^n_v = \sum_{\subalign{e \in E \\ d \left( e_d, v \right) &= n \\ d \left( e_o, v \right) &= n + 1 }} \calls_e \\
	\end{aligned}
\label{eq:higher_order_user_data}
\end{equation}

This definition can be seen more intuitively in the graph in \cref{fig:higherorderuserdata}.

\begin{figure}
\centering
\framebox{%
	\input{figures/ego.tikz}
}
\caption{Example of the edges present in the calculation of the \emph{Higher Order User Data} for a certain node $v$. \textcolor{red}{Red} edges represent edges whose features are accumulated in the \emph{User Data of Order 0}, \textcolor{blue}{blue} edges represent those of \emph{Order 1}, and \textcolor{ForestGreen}{green} those of \emph{Order 2}.}
\label{fig:higherorderuserdata}
\end{figure}

Every set $\ego_n$ contains features from that level and all the previous ones as presented formally in \cref{eq:formal_higher_order}. This implies that, if the prediction algorithms are smart enough, the result of using the features from $\ego_{n + 1}$ should be at least as good as using the ones from $\ego_n$.

\begin{equation}
	(\forall n \in \mathbb{N}) \ego_n \subset \ego_{n + 1}
\label{eq:formal_higher_order}
\end{equation}

In one of the initial experiments in this thesis we added more features related to the $\left\{ \text{in}, \text{out} \right\}$ group to indicate how many ``in'' or ``out'' edges must be traversed from $\upsilon$. However, this added an exponentially large new amount of features without much significant data, and thus was left out from the following experiments.

\subsection{Higher Order Categorical User Data --- Level $\cat_{n > 0}$}

It is possible to combine the ideas in \cref{subsec:categoricaluserdata,subsec:higherorderuserdata} to create a group of sets of features containing the data from the border of the \emph{Ego Network or Order $n$}, separated by two disjoint groups depending in the category of the node outside the ego network, as in \cref{eq:formal_higher_order_categorical}, with $E$ defined as in \cref{sec:dataset} as the set of edges where $e_o$ is the user that originated a call and $e_d$ the user in the destination.

\begin{equation}
	\begin{aligned}
		\incallslow^n_v = \sum_{\subalign{e \in &E \\ e_d \in &H_1 \\ d \left( e_o, v \right) &= n \\ d \left( e_d, v \right) &= n + 1}} \calls_e &\quad
		\incallshigh^n_v = \sum_{\subalign{e \in &E \\ e_d \in &H_2 \\ d \left( e_o, v \right) &= n \\ d \left( e_d, v \right) &= n + 1}} \calls_e \\
		\outcallslow^n_v = \sum_{\subalign{e \in &E \\ e_o \in &H_1 \\ d \left( e_d, v \right) &= n \\ d \left( e_o, v \right) &= n + 1}} \calls_e &\quad
		\outcallshigh^n_v = \sum_{\subalign{e \in &E \\ e_o \in &H_2 \\ d \left( e_d, v \right) &= n \\ d \left( e_o, v \right) &= n + 1}} \calls_e \\
	\end{aligned}
\label{eq:formal_higher_order_categorical}
\end{equation}

Using these features we can have a more complete understanding of the data surrounding each node $v$.
In \cref{sec:comparison_results}, where we present the final results, we prove that the best predictor between all the methods explored in this chapter is this same method defining when using a \emph{Random Forest} to predict the final labels, both when using the inner graph (and using only the ego network when $n = 1$) and when using the entire outer graph (and using the ego network with $n = 2$).

The amount of features grows exponentially in each step (see \cref{tab:datasettable}), and so does the time spent in each computation. Since the best results are found with metrics when looking at the \emph{Ego Network} of level 1 of the inner graph (that is, the information contained in the edges of the neighbours of the neighbours of each node), which can be explained by the fact that the noise of the information about users far away from the noise has more impact than the useful information, no tests were attempted in cases where $n \geq 3$.

\section{Machine Learning Methods}

All the feature sets described in the previous sections are individually going to be used as the input objects of the \emph{Training Data} and either the \emph{Outer Graph} $\Omega$ or the \emph{Inner Graph} $\Upsilon$ will be used as the output with several \emph{Supervised Machine Learning} methods. The result of these methods will be measured using many metrics of the results, previously described in \cref{subsec:mlmetrics}, and compared against other methods (including the Bayesian Algorithm of \cref{sec:inference_methodology}) in \cref{sec:comparison_results}.

To prevent the problem of \emph{Overfitting} the results are generated by using \emph{Cross-Validated} estimates of the data using \emph{K-Folds} with $K = 5$. This way, each quintile of the data is predicted using only data from the other four.

The two methods used in this thesis, \emph{Logistic Regression} and \emph{Random Forest} tend to have different variance in the results~\cite{ting2016}, therefore different sources of errors may end up decreasing the models accuracy differently. This is a good for our model, since it means that a single source of errors has less probability of affecting either predictor.

These \emph{Machine Learning} methods used in this section contain many hyperparameters which may affect the result, and calculating the optimal value for them isn't trivial. For this reason this experiment includes a \emph{Grid Search} of the data against all possible hyperparameters. The resulting hyperparameters of the \emph{Grid Search} are presented in \cref{tab:gridsearch}.

\begin{table}
\centering
\begin{tabular}{>{\bfseries}c >{\bfseries}l >{\hspace{3em}}r r r r r r}
\toprule
\multirow{2}{*}{Data} & \multirow{2}{*}{Level} & \multicolumn{3}{>{\hspace{1em}}c}{\textbf{Log. Regression}} & \multicolumn{3}{>{\hspace{2em}}c}{\textbf{Random Forest}} \\
&& \phantom & $\log_{10}{\left(C\right)}$ && Criterion & Features & W/Replacement \\
\midrule
\multirow{5}{*}{$\Upsilon$}
& $\ego_0$ & & $-2$ & & Entropy &  $\sqrt{f}$ & True \\
& $\ego_1$ & & $-2$ & & Entropy &         $f$ & True \\
& $\ego_2$ & & $-2$ & & Entropy &         $f$ & True \\
& $\cat_0$ & & $-3$ & & Entropy & $\log_2{f}$ & True \\
& $\cat_1$ & &  $0$ & & Entropy &         $f$ & True \\
& $\cat_2$ & & $-1$ & & Entropy &         $f$ & True \\
[2ex]
\multirow{5}{*}{$\Omega$}
& $\ego_0$ & &  $0$ & & Gini    & $\log_2{f}$ & True \\
& $\ego_1$ & &  $1$ & & Entropy & $\log_2{f}$ & True \\
& $\ego_2$ & &  $0$ & & Entropy &  $\sqrt{f}$ & True \\
& $\cat_0$ & & $-2$ & & Entropy & $\log_2{f}$ & True \\
& $\cat_1$ & &  $2$ & & Gini    &  $\sqrt{f}$ & True \\
& $\cat_2$ & &  $2$ & & Entropy & $\log_2{f}$ & True \\
\bottomrule
\end{tabular}
\caption{Best hyperparameters for each group of features in each model used for predicting the result.}
\label{tab:gridsearch}
\end{table}

\subsection{Logistic Regression}

The method of \emph{Logistic Regression}, which is described with more detail in \cref{subsec:logisticregression}, consists of doing some regression analysis with the data after applying some \emph{Logistic Function} to normalize the data.

The most important hyperparameter of this data is the \emph{Regularization Factor} $C$, which specifies the regularization of the input. As shown in \cref{eq:gridsearchlogreg}, this value is searched in exponential increments.

\begin{equation}
\label{eq:gridsearchlogreg}
C \in \left\{ 10^{-3}, 10^{-2}, 10^{-1}, 10^0, 10^1, 10^2, 10^3 \right\}
\end{equation}

Since the different data aren't linearly distributed, the input is \emph{Regularized} before using this method so that, when running the model, each column has its mean in $\mu = 0$ and its variance $\sigma^2 = 1$. This makes the model more robust~\cite{mitchellml1997}.

\subsection{Random Forest}
\label{subsec:comparison_random_forest}

The method of \emph{Random Forest}, which is described with more detain in \cref{subsec:randomforest}, consists of constructing a multitude of \emph{Decision Trees} and outputting the class that is the \emph{mode} of the classes.

There are several hyperparameters used in this method, namely the \texttt{Criterion} to measure the quality of a split (\texttt{gini} uses Gini impurity, while \texttt{entropy} uses information gain), the function used to calculate the \texttt{Sample Size} given the amount of features $f$, and whether the samples are taken with or without \texttt{Replacement}. This is formalized in \cref{eq:gridsearchrandomforest}.

Another possible hyperparameter would be the number of trees. However, as it is been shown in~\cite{breiman2001random}, \emph{Random Forests} converge quickly for a high amount of trees. Since the objective of this section isn't to optimize by time, the value will be set to the sufficiently high $\text{\texttt{n\_estimators}} = 50$.

\begin{equation}
\label{eq:gridsearchrandomforest}
\begin{aligned}
	\operatorname{Criterion} &\in \left\{ \operatorname{Gini}, \operatorname{Entropy} \right\} \\
	\operatorname{Features} &\in \left\{ f, \sqrt{f}, \log_2{f} \right\} \\
	\operatorname{Replacement} &\in \left\{ \operatorname{True}, \operatorname{False} \right\}
\end{aligned}
\end{equation}

\section{Validation Metrics}
\label{subsec:validationmetrics}
There are several validation metrics used for each method.

\begin{description}
	\item[Accuracy] (Acc.) as described in \cref{subsec:accuracy}, which measures the general performance of this method.
	\item[Precision] (Prec.) as described in \cref{subsec:precisionrecall}, which measures the performance regarding the positive instances found by this method.
	\item[Recall] (Rec.) as described in \cref{subsec:precisionrecall}, which measures the performance regarding the positive instances in the dataset.
	\item[Area Under the Curve] (AUC) as described in \cref{subsec:auc}, which measures the general performance disregarding which threshold is used.
	\item[$\mathbf{F_1}$ Score] (F\textsubscript{1}) as described in \cref{subsec:fmeasure} which is generalized score balancing Precision and Recall.
	\item[$\mathbf{F_4}$ Score] (F\textsubscript{4}) as described in \cref{subsec:fmeasure}, which gives more weight to the Recall. This is usually wanted since the ultimate practical objective of this study is to find wealthier people, even if the result has low Precision.
	\item[Fit Time] (t\textsubscript{fit}) is the time it takes to fit a model. It is particularly high in ensemble methods such as \emph{Random Forest}.
	\item[Predict Time] (t\textsubscript{predict}) can be used to break ties between similar models.
\end{description}

\section{Results}
\label{sec:comparison_results}

\subsection{Inner Graph}
\label{subsec:comparison_inner_graph}

\Cref{tab:innercomparison} shows various metrics which result from applying the methods described in this section to the datasets presented in this thesis as the \emph{Inner Graph} $\Upsilon$, which contains the subset of people where at least one neighbour contains socioeconomic data.

\begin{table}[tbh]
\centering
\input{inner_graph_table}
\caption{Resulting metrics of different methods used in \cref{sec:results,sec:comparison} tested on the \emph{Inner Graph} $\Upsilon$, which contains only nodes which have at least one neighbour with socioeconomic information. \textbf{Bolded} items represent the highest value for each metric.}
\label{tab:innercomparison}
\end{table}

By comparing only the methods based in \emph{Machine Learning}, we can reach a conclusion consistent with the one reached by Muchlinski et~al.~\cite{muchlinski2016}, where the methods based in \emph{Random Forest} tend to perform better in real-world scenarios than the ones based in \emph{Logistic Regression}.

The model based in \emph{Random Forest} has better results in all metrics when comparing the datasets of $\ego_0$ and $\ego_1$, that is, when making the \emph{Ego Network} of users where data is collected one degree bigger.
Interestingly, not only these results aren't repeated when comparing the following two levels ($\ego_1$ and $\ego_2$), but most metrics, including \emph{Area Under the Curve}, show a slight decrease.
While this means that an extra degree of data adds no useful information instead of just noise, using this data it is possible to see the fallibility of common \emph{Random Forest} fitting methods, as this regression shouldn't be possible since $\ego_2 \supset \ego_1$ and the noise features could have been ignored by the hypothetical perfectly-trained classifier.

The results are worse in all metrics of the $\ego$ datasets when predicting using a \emph{Logistic Regression} method.
One possible cause of this is that the \emph{Random Forest} classifier is more versatile to odd cases and non-linear data when compared to the other classifier~\cite{logisticvsdecision}.
The fact that there is almost a null increase in the metrics when going down the graph seems to ratify this decision.

By far, the greatest increase in results for the methods based in \emph{Machine Learning} presented in \cref{sec:comparison} is adding labels related to the accumulated features separated by the neighbours' socioeconomic index, as in the levels $\cat_0$ to $\cat_2$.
This shows that, in problems related to real data in graphs, there are better results when using  more informative features taken from the same subset of data than taking data from a bigger \emph{Ego Network}.

When using categorical methods, predicting with features extracted from the set $\cat_1$ resulted in better values for almost every metric than using features extracted from the set $\cat_2$.
As in the previous point about comparing $\ego_1$ and $\ego_2$, getting features about the links of users further away than 2 degrees adds more noise than useful information to the dataset. Indeed, this is the reason why the experimentation stopped at this degree instead of going one level further in the \emph{Ego Network}.

The most remarkable part of these results is that, even in the best case scenario, \textbf{the results for any of the methods based in \emph{Machine Learning} presented in \cref{sec:comparison} are worse than the ones from the \emph{Bayesian Algorithm} presented in \cref{sec:inference_methodology}}.
This is remarkable since the latter method uses a much lower amount of features per node (2 vs 48 in the case of $\cat_1$) and takes a shorter amount of time predicting data than the best of the former methods takes to train a classifier on it.

Further conclusions related to this last point are discussed in \cref{chap:conclusions}.

\subsection{Outer Graph}

\Cref{tab:outercomparison} shows various metrics which result from applying the metrics described in this section to the datasets presented in this thesis as the \emph{Outer Graph} $\Omega$, which contains the entire \emph{Social Graph} $G$, including the majority of nodes for which no socioeconomic data is known about their neighbours.
This makes it impossible to run the \emph{Bayesian Algorithm} presented in \cref{sec:inference_methodology}, as it uses this data directly as features.

\begin{table}[tb]
\centering
\input{outer_graph_table}
\caption{Resulting metrics of different methods used in \cref{sec:comparison} tested in the \emph{Outer Graph} $\Omega$, which includes all nodes. \textbf{Bolded} items represent the highest value for each metric.}
\label{tab:outercomparison}
\end{table}

The relative results between different \emph{Machine Learning} and feature extraction methods are similar to the ones presented for the \emph{Inner Graph} presented in \cref{subsec:comparison_inner_graph}.
However, since there is a significant amount of new users without much significant information the absolute results are considerably worse.

Like in \cref{subsec:comparison_inner_graph}, adding an single level to the size of the original \emph{Ego Network} improved the values of all metrics, since more useful data was used to generate the features.
This is truth both when using only general general features (which are present for all users in $\Omega$) as seen in the difference between $\ego_0$ and $\ego_1$, and when using socioeconomic data in the features (where most users have all metrics equal to 0, as there is no information) as in between $\cat_0$ and $\cat_1$.

Interestingly, unlike the results in \cref{tab:innercomparison}, all metrics keep improving when making the \emph{Ego Network} another level deeper ($\ego_2$ and $\cat_2$).
The reason for this is a simple matter of biases between the \emph{Inner Graph} and the \emph{Outer Graph}: users present in the latter graph ($\Omega \setminus \Upsilon$) tend to have less contacts in general than the rest.
This makes the first few levels of the \emph{Ego Network} contain less useful data to use as \emph{Machine Learning} features, while the relatively noisy features generated from the latter levels actually improves these.

Like in the previous table, \emph{Machine Learning} methods that use \emph{Random Forest} have a considerable advantage over all metrics compared to the ones using \emph{Logistic Regression}, using features related to the \emph{Socioeconomic Level} of a users' neighbour improves the results.
However, due to the amount of users without any significative data about their neighbours, the difference is small compared to the one in \cref{tab:innercomparison}.
