\section{Results}

% \subsection{Validation Process}

%We need to make sure that our inference algorithm correctly predicts users' income in each of the 5 categories $ H_1, \ldots, H_5 $. According to our hypothesis, the greater the amount of calls to , this increases the probability that both of them will belong to the same group.

%For each link $ p = \left< p_o, p_d, \ldots \right> \in P $, our hypothesis says that $ p_o $ and $ p_d $ will belong to the same income group. 

%In order to validate our proposed methodology, we take advantage of the computed $p_lower$ for each user and use this quantity as the predicition score that allow us to evaluate whether a given user belongs to one of the deffined categories. A standarized way to quantify the performace of the metodology is by computing Receiver Operating Characteristic Curve (ROC). This curve  

We describe in this section the validation of our methodology. 
We examine the true positive ($TPR$) and false positive ($FPR$) rates: 
$$TPR=TP/P \; \; \mbox{ and } \; \;  FPR=FP/N$$ 
where $TP$ is the number of correctly predicted users with high income, $P$ is the total number of users with high income, $FP$ is the number of users incorrectly classified as having high income, and $N$ is the total number of users with low income. 

In Figure~\ref{ROC_multiclass} we plot the ROC (\textit{Receiver Operating Characteristic}) curve, showing $TPR$ and $FPR$ for the set of possible values of $\tau$. We see that our methodology clearly outperforms random guessing (dashed straight line). We can summarize our performance by calculating  the AUC (\textit{Area Under the Curve}) which in Figure~\ref{ROC_multiclass} is $AUC = 0.74$. Note that random guessing would give a value of $AUC \simeq 0.50$.


%\vspace{1em}
%
%\begin{adjustwidth}{-1.5cm}{}
%\begin{tabu} to \textwidth { r X[c] X[c] }
%& \multicolumn{2}{ c }{\textbf{Classifier result for income group $ H_i $}} \\
%\\
%& Caller in group & Caller not in group \\
%Callee in group & \cellcolor{green} True Positive & \cellcolor{red} \makecell{False Negative \\ (Type II Error)} \\ 
%Callee not in group & \cellcolor{red} \makecell{False Positive \\ (Type I Error)} & \cellcolor{green} True Negative \\
%\end{tabu}
%\end{adjustwidth}

%To validate these classifiers, we use 

%a \textbf{Receiver Operating Characteristic Curve} (ROC) to plot the \textbf{True Positive Rate} and the \textbf{False Positive Rate} of each system. Since the amount of people in each group is almost equal, randonly guessing each user's income would result in a diagonal line.

%As an objective measurement, we can calculate the \textbf{Area under the curve} for each income group as the chance that the classifier would make a better prediction of the composition of this income group better than a random one. For this we define the density functions $ f_i(x) $ as the probability that a user will be considered part of the income group $ H_i $, and $ g_i(x) $ as the probability that it won't. This way we can characterize the True Positive Rate and the False Positive Rate for each group as

%\vspace{-1em}
%
%\begin{align*}
%\operatorname{TPR}_i(T) &= \int^{\infty}_T f_i(x) dx \\
%\operatorname{FPR}_i(T) &= \int^{\infty}_T g_i(x) dx \\
%\end{align*}
%
%\vspace{-1.5em}

%With this two functions, we can define the AUC for each category as as a simple integration:

%\[
%A_i = P(X_1 > X_0) = \int^{-\infty}_{\infty} \operatorname{TPR_i}(T) \operatorname{FPR_i}(T) dT
%\]

%Where $ X_1 $ is the score for a positive instance, and $ X_0 $ is the score for a negative one.

%\subsection{Results}

\begin{figure}[H]
\begin{center}
\includegraphics[width=\columnwidth]{figures/ROC_BETA/ROC_Beta_based_approach_201504.png}
\caption{ROC curve for prediction procedure. We observed an $AUC = 0.74$ indicating that our predictor is better than a random predictor ($AUC \simeq 0.50$).}
\label{ROC_multiclass}
\end{center}
\end{figure}

%The result ROC curves have the following areas:
%
%\vspace{-1em}
%
%\begin{align*}
%A_1 &= 0.68 & A_2 &= 0.69 & A_3 &= 0.63 \\ 
%A_4 &= 0.68 & A_5 &= 0.69
%\end{align*}
%
%As evidenced by figure \ref{ROC_multiclass}, the inference process seems to have been successful: the predicted value is much better than one predicted by a random classifier for all of the categories.
